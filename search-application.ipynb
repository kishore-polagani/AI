{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3266e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6556e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b26d1d1",
   "metadata": {},
   "source": [
    "# search application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edddee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Integrate our code OpenAI API\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# streamlit framework\n",
    "\n",
    "input_text=input(\"Search the topic u want\")\n",
    "\n",
    "# Prompt Templates\n",
    "\n",
    "first_input_prompt=PromptTemplate(\n",
    "    input_variables=['name'],\n",
    "    template=\"Tell me about celebrity {name}\"\n",
    ")\n",
    "\n",
    "# Memory\n",
    "\n",
    "person_memory = ConversationBufferMemory(input_key='name', memory_key='chat_history')\n",
    "dob_memory = ConversationBufferMemory(input_key='person', memory_key='chat_history')\n",
    "descr_memory = ConversationBufferMemory(input_key='dob', memory_key='description_history')\n",
    "\n",
    "## OPENAI LLMS\n",
    "llm=OpenAI(temperature=0.8)\n",
    "chain=LLMChain(\n",
    "    llm=llm,prompt=first_input_prompt,verbose=True,output_key='person',memory=person_memory)\n",
    "\n",
    "# Prompt Templates\n",
    "\n",
    "second_input_prompt=PromptTemplate(\n",
    "    input_variables=['person'],\n",
    "    template=\"when was {person} born\"\n",
    ")\n",
    "\n",
    "chain2=LLMChain(\n",
    "    llm=llm,prompt=second_input_prompt,verbose=True,output_key='dob',memory=dob_memory)\n",
    "# Prompt Templates\n",
    "\n",
    "third_input_prompt=PromptTemplate(\n",
    "    input_variables=['dob'],\n",
    "    template=\"Mention 5 major events happened around {dob} in the world\"\n",
    ")\n",
    "chain3=LLMChain(llm=llm,prompt=third_input_prompt,verbose=True,output_key='description',memory=descr_memory)\n",
    "parent_chain=SequentialChain(\n",
    "    chains=[chain,chain2,chain3],input_variables=['name'],output_variables=['person','dob','description'],verbose=True)\n",
    "\n",
    "\n",
    "if input_text:\n",
    "    print(parent_chain({'name': input_text}))\n",
    "\n",
    "    print(\"Person Name:\")\n",
    "    print(person_memory.buffer)\n",
    "\n",
    "    print(\"Major Events:\")\n",
    "    print(descr_memory.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe60e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.8)\n",
    "\n",
    "# User input\n",
    "input_text = input(\"Enter the topic you want to search: \")\n",
    "\n",
    "# Generate output\n",
    "if input_text:\n",
    "    output_text = llm(input_text)\n",
    "    print(\"Output:\")\n",
    "    print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "form langchain.llms import opentracing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f0388",
   "metadata": {},
   "source": [
    "# pdf query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd15b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b345cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89340acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7484a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39b03d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8169030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1391656e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b761dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
